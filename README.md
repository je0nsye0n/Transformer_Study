# Transformer_Study

- 기간 : 25.01.13 ~   
- Ref : [Paper](https://arxiv.org/abs/1706.03762), [교재](https://wikibook.co.kr/pytorchtrf/), [harvardnlp](https://nlp.seas.harvard.edu/2018/04/03/attention.html)

---
### 공부 내용 기록
  

| Date | Content |
|-------|-------|
| 01.13 | 주교재로 트랜스포머 정리 | 
| 01.14 | Transformer paper code review, Encoder code : Py2C |
| 01.15~16 | C로 fclayer 동작 |
| 01.17 | transformer python 코드 수정 - 정확도 이슈 & 모듈 따로 구현해봄(pos_enc, attention)|
| 01.20 | 모듈 1차 구현 |
| 01.21~ | 검증 및 디버깅 + Transformer Encoder 모델 python으로 정리 |
